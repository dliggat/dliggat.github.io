<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Https | Liggat.org]]></title>
  <link href="http://liggat.org/blog/categories/https/atom.xml" rel="self"/>
  <link href="http://liggat.org/"/>
  <updated>2015-01-09T08:26:57-08:00</updated>
  <id>http://liggat.org/</id>
  <author>
    <name><![CDATA[Dave Liggat]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[HTTPS: Emulate the Newspaper]]></title>
    <link href="http://liggat.org/2015/01/07/https-emulate-the-newspaper/"/>
    <updated>2015-01-07T20:47:11-08:00</updated>
    <id>http://liggat.org/2015/01/07/https-emulate-the-newspaper</id>
    <content type="html"><![CDATA[<p>There&rsquo;s a pretty substantial effort around the Internet to get <a href="http://en.wikipedia.org/wiki/Transport_Layer_Security">SSL/TLS</a> (i.e. <a href="http://en.wikipedia.org/wiki/HTTP_Secure">HTTPS</a> as far as the web is concerned) deployed as widely as possible in favour of unencrypted-<a href="http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol">HTTP</a>. I won&rsquo;t enumerate the reasons here, though I will direct the reader to <a href="https://www.tbray.org/ongoing/misc/Tim">Tim Bray</a>&rsquo;s excellent <a href="https://www.tbray.org/ongoing/When/201x/2012/12/02/HTTPS">Private by Default</a> post on the topic.<!--more--></p>

<p>This issue was further covered for a couple of weeks by the folks on the <a href="http://atp.fm">ATP podcast</a>; in particular they <a href="http://atp.fm/episodes/97">discussed</a> the issue of whether HTTPS is worth bothering with on mostly-or-entirely static endpoints such as blogs or news sites. They mentioned a number of excellent points, including the use of HTTPS as a mechanism to defeat, or at least hinder, the repellent practice of a <a href="http://en.wikipedia.org/wiki/Man-in-the-middle_attack">man-in-the-middle</a> injecting <a href="https://www.eff.org/deeplinks/2014/11/verizon-x-uidh">ad tracking codes</a> into the unencrypted-HTTP payloads, or otherwise monkeying with the payload in any way en-route to its client.</p>

<p>Between these and other worthwhile discussions of the issue, I don&rsquo;t have a great deal to add, especially since <a href="http://en.wikipedia.org/wiki/Information_security">infosec</a> is a discipline for which I have nothing but personal interest to purvey as a credential. However, an analogy did recently occur to me, and though it&rsquo;s clearly <a href="#flawed">flawed</a>, as are all analogies, it just might be a helpful way to think about the issue.</p>

<p>Imagine a mailbox, attached to a house. The occupant is an enthusiastic reader; and subscribes to a substantial bundle of newspapers. Daily, the occupant retrieves the newspapers, brings them into the house, and behind closed doors engages in an leisurely perusal of their contents.</p>

<p>Any observer of this ritual – from the delivering postal-worker to the binoculared-neighbour on the lookout for prurient gossip – is only able to gain <em>limited</em> insight into the interests of the occupant. Certainly, the newspapers themselves leak information about the occupant – conclusions are immediately drawn upon witnessing the various publication titles, and the personal interests and perhaps even personality characteristics that their <a href="http://en.wikipedia.org/wiki/Union_%28set_theory%29">union</a> implies.</p>

<p>But that&rsquo;s as far as it goes. <em>Crucially</em> – no observer is privy to the set of <em>actual articles</em> that pique the occupant&rsquo;s interest, and the time spent reading each one. It is between the occupant and the bundle itself how high-brow, or how low-brow those interests are, how much time is spent on world affairs versus comics and sports, whether any lingering on the seedier classifieds goes on, and so on.</p>

<p>It&rsquo;s undoubtedly clear where this is going: hosts on the Internet are newspapers, and URLs are articles. Host visitation may well be visible to the observer; URL visitation should not be. It is entirely reasonable to demand that the Internet should seek to emulate, at a minimum, a comparable privacy affordance to that which naturally exists in the newspaper scenario. Asterisks and fine-print abound, but HTTPS brings this newspaper-esque privacy to the web.</p>

<p>Given the extent to which life – personal, civic, political and otherwise – has moved, and continues to move online, private-by-default is a crucial and long-overdue evolutionary step for the Internet. Whether any given site is largely &lsquo;static&rsquo; or not – it&rsquo;s a distinction that&rsquo;s ultimately irrelevant.</p>

<h3><a name="flawed" class="target">Addendum I</a></h3>


<p><em>Of course the analogy breaks comprehensively upon casual analysis: newspapers don&rsquo;t have certificate authorities and the attendant hassles; it&rsquo;s hard to fail at privately readingly newspapers but easy to fail at deploying and consuming TLS; things like <a href="http://heartbleed.com/">Heartbleed</a> happen, etc. It&rsquo;s also the case that without particular care taken, the <a href="http://security.stackexchange.com/questions/73309/do-payload-sizes-reveal-urls-when-https-is-deployed-on-news-blogs-etc">unique payload</a> sizes for the set of site URLs will be able to imply URL visitation anyhow. And perhaps most obviously: the newspaper itself doesn&rsquo;t receive requests for which individual articles you&rsquo;d like you read.</em></p>

<h3>Addendum II</h3>

<p><em>I&rsquo;m very vulnerable to charges of hypocrisy, or at least neglect – this very site has no HTTPS endpoint. That&rsquo;ll be rectified this year &ndash; probably as a test case for when the <a href="https://letsencrypt.org/">Let&rsquo;s Encrypt</a> Certificate Authority launches.</em></p>
]]></content>
  </entry>
  
</feed>
